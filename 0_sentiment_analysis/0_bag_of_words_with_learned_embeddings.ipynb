{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of IMDb movie reviews\n",
    "\n",
    "# Bag-of-words model with learned embeddings\n",
    "\n",
    "## Learnings:\n",
    "\n",
    "At the end of this lesson you will know:\n",
    "\n",
    "- How to create a bag-of-words model for sentiment analysis.\n",
    "\n",
    "- How to feed text data into a PyTorch model using `torchtext`\n",
    "\n",
    "- How to write a training/validation loop in PyTorch.\n",
    "\n",
    "- How to visualize training metrics and word embeddings with Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Paulescu/practical-nlp-2021/blob/main/notebooks/1_fine_tune_bert_for_sentiment_analysis.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Data download and pre-processing\n",
    "\n",
    "The original dataset in `http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz` has one file per example, and examples are grouped in folders according to train vs test, and positive vs negative.\n",
    "\n",
    "At the end of `Stage 1: Data pre-processing` we will have data split into 3 CSV files: train.csv, validation.csv, test.csv. In each file, the first column will be the review text, the second column will\n",
    "be the sentiment, 0: negative, 1: positive. This is the format we need the data to be to use `torchtext` data ingestion convenient function `TabularDataset.splits()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-08 17:49:39--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
      "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 84125825 (80M) [application/x-gzip]\n",
      "Saving to: ‘aclImdb_v1.tar.gz.2’\n",
      "\n",
      "aclImdb_v1.tar.gz.2 100%[===================>]  80.23M  3.40MB/s    in 24s     \n",
      "\n",
      "2020-12-08 17:50:04 (3.28 MB/s) - ‘aclImdb_v1.tar.gz.2’ saved [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read raw data from disk into Python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_texts:  25000\n",
      "test_texts:  25000\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "def read_imdb_split(split_dir: str) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Auxiliary function to read raw data from disk\n",
    "    into 2 Python lists, one for texts the other for labels\n",
    "    \"\"\"\n",
    "    split_dir = Path(split_dir)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for label_dir in ['pos', 'neg']:\n",
    "        for text_file in (split_dir/label_dir).iterdir():\n",
    "            texts.append(text_file.read_text())\n",
    "            labels.append(0 if label_dir is \"neg\" else 1)\n",
    "    return texts, labels\n",
    "\n",
    "train_texts_, train_labels_ = read_imdb_split('aclImdb/train')\n",
    "print('train_texts: ', len(train_texts_))\n",
    "\n",
    "test_texts, test_labels = read_imdb_split('aclImdb/test')\n",
    "print('test_texts: ', len(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_texts:  20000\n",
      "val_texts:  5000\n",
      "test_texts:  25000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = \\\n",
    "    train_test_split(train_texts_, train_labels_, test_size=0.2, random_state=1)\n",
    "\n",
    "print('train_texts: ', len(train_texts))\n",
    "print('val_texts: ', len(val_texts))\n",
    "print('test_texts: ', len(test_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `train.csv` , `validation.csv`, `test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.DataFrame({'text': train_texts, 'label': train_labels},\n",
    "                          columns=['text', 'label'])\n",
    "val_data = pd.DataFrame({'text': val_texts, 'label': val_labels},\n",
    "                        columns=['text', 'label'])\n",
    "test_data = pd.DataFrame({'text': test_texts, 'label': test_labels},\n",
    "                         columns=['text', 'label'])\n",
    "\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "val_data.to_csv('val_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: Define PyTorch `Dataset` and `DataLoader`s using `torchtext`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `Field` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/src/online-courses/practical-nlp-2021/awesome-nlp/.venv/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/Users/paulabartabajo/src/online-courses/practical-nlp-2021/awesome-nlp/.venv/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize='spacy', lower=True, batch_first=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `Dataset` objects for train, validation, test files\n",
    "\n",
    "A `Dataset` is a list of `Example` objects. Each `Example` is a dictionary that maps `Field` names to values.\n",
    "\n",
    "`TabularDataset` provides a convenient way to load columnar data from a csv file into a PyTorch `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/src/online-courses/practical-nlp-2021/awesome-nlp/.venv/lib/python3.7/site-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n",
      "/Users/paulabartabajo/src/online-courses/practical-nlp-2021/awesome-nlp/.venv/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "fields = [('text', TEXT), ('label', LABEL)]\n",
    "\n",
    "train, val, test = TabularDataset.splits(\n",
    "    path='',\n",
    "    train='train_data.csv',\n",
    "    validation='val_data.csv',\n",
    "    test='test_data.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=fields,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.dataset.TabularDataset'>\n",
      "<class 'torchtext.data.dataset.Dataset'>\n",
      "<class 'torch.utils.data.dataset.Dataset'>\n",
      "<class 'torchtext.data.example.Example'>\n"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "\n",
    "print(type(train))\n",
    "print(TabularDataset.__bases__[0])\n",
    "print(torchtext.data.dataset.Dataset.__bases__[0])\n",
    "print(type(train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access each example data in the same way you access elements of a Python `list`\n",
    "and attributes of a Python `object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  ['there', 'are', 'so', 'many', 'good', 'things', 'to', 'say', 'about', 'this', '“', 'b', '”', 'movie.<br', '/><br', '/>“b', '’', 'maybe', 'in', 'connections', ',', 'but', 'not', 'in', 'commission', '.', 'this', 'is', 'about', 'the', 'best', 'of', 'its', 'genre', 'that', 'i', 'have', 'ever', 'seen', '.', 'a', 'grade', 'a', 'effort', 'by', 'universal', '.', 'the', 'script', 'is', 'well', 'done', ',', 'imaginative', ',', 'and', 'without', 'fault', '.', 'writing', 'credits', ':', 'howard', 'higgin', 'original', 'story', '&', 'douglas', 'hodges', 'story', ',', 'john', 'colton', '(', 'screenplay', ')', '.', 'director', 'lambert', 'hillyer', 'handled', 'the', 'complex', 'story', 'and', 'story', 'locations', 'very', 'well', '.', 'no', 'skimping', 'on', 'the', 'loads', 'of', 'extras', 'and', 'locations', '.', 'i', 'loved', 'beulah', 'bondy', '(', 'jimmy', 'stewarts', 'mother', 'in', '“', 'it', '’s', 'a', 'wonderful', 'life', '”', '.', 'the', 'fem', 'lead', ',', 'frances', 'drake', 'is', 'a', 'beauty', 'and', 'handled', 'her', 'part', 'with', 'grace', 'and', 'pathos', 'for', 'her', 'karloff', 'husband', '.', 'lugosi', 'likewise', 'was', 'correctly', 'underplayed', '.', 'i', 'think', 'this', 'is', 'the', 'best', 'part', 'i', 'remember', 'seeing', 'him', 'in', '.', 'as', 'i', 'said', 'there', 'were', 'so', 'many', 'good', 'things', ':', 'the', 'african', 'discovery', 'of', 'the', 'radium', '“', 'x', '”', ',', 'the', 'melting', 'of', 'the', 'stone', 'statues', '(', '(', 'somewhat', 'reminiscent', 'of', 'the', 'ten', 'little', 'indians', 'in', 'and', 'then', 'there', 'were', 'none', '(', 'agatha', 'christie', ')', '(', 'the', 'barry', 'fitzgerald', 'version', ')', ')', ',', 'the', 'glowing', 'of', 'karlof', 'in', 'the', 'dark', '.', 'karloff', '’s', 'mother', 'played', 'by', 'violet', 'kemble', 'cooper', 'with', 'elegance', '.', 'and', 'because', 'of', 'all', 'these', 'virtues', ',', 'i', 'found', 'myself', 'believing', 'in', 'the', 'science', 'it', 'portrayed', '.', 'i', 'guess', 'that', '’s', 'the', 'mark', 'of', 'a', 'good', 'piece', 'of', 'art', '.']\n",
      "\n",
      "label:  1\n"
     ]
    }
   ],
   "source": [
    "print('text: ', train[0].text)\n",
    "print('\\nlabel: ', train[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vocabulary using the training data\n",
    "\n",
    "A `Vocab` object maps each word in the training set into a unique integer.\n",
    "\n",
    "Once you build the vocabulary you can express sentences as sequences of integers.\n",
    "\n",
    "Only training data is used to generate the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, max_size=10000, min_freq=2)\n",
    "\n",
    "# we will need this later\n",
    "vocab_size = len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can map words to integers, and viceversa, using the dictionaries `Vocab.itos` and `Vocab.stoi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[13])\n",
    "print(TEXT.vocab.stoi['this'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train/validation/test dataloaders\n",
    "\n",
    "In `torchtext` data loaders are called `BucketIterator`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/src/online-courses/practical-nlp-2021/awesome-nlp/.venv/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train, val, test),\n",
    "    batch_sizes=(batch_size, batch_size, batch_size),\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    sort_within_batch=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is `train_iter`?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtext.data.iterator.BucketIterator'>\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.text]:[torch.LongTensor of size 128x661]\n",
      "\t[.label]:[torch.LongTensor of size 128] \n",
      "\n",
      "text: \n",
      " tensor([[2390,    0,    3,  ..., 1828, 1761,    4],\n",
      "        [   0,   91,  382,  ...,    0,   18, 7875],\n",
      "        [1610, 5653,    3,  ..., 2674,   18, 7572],\n",
      "        ...,\n",
      "        [  57,   27,  591,  ...,    1,    1,    1],\n",
      "        [  21,  170,   12,  ...,    1,    1,    1],\n",
      "        [  10,   19,    6,  ...,    1,    1,    1]])\n",
      "label: \n",
      " tensor([1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
      "        0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "        0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 0, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulabartabajo/src/online-courses/practical-nlp-2021/awesome-nlp/.venv/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# it is an iterator\n",
    "print(type(train_iter))\n",
    "\n",
    "# let's pick the first element and check what it is inside\n",
    "x = next(iter(train_iter))\n",
    "print(x, '\\n')\n",
    "print('text: \\n', x.text)\n",
    "print('label: \\n', x.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Define the neural net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add diagram here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_dim: int):\n",
    "        super(Model, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.global_avg_pooling = lambda x: torch.mean(x, dim=-2)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Model(vocab_size, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 26106), started 0:01:44 ago. (Use '!kill 26106' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-70eba72f168f239c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-70eba72f168f239c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:15<00:00, 10.04it/s]\n",
      "  1%|          | 1/157 [00:00<00:17,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train loss: 0.2697 \t Train accuracy: 0.8936\n",
      "Val loss: 0.3524 \t Val accuracy: 0.8564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 10.94it/s]\n",
      "  1%|▏         | 2/157 [00:00<00:10, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Train loss: 0.2678 \t Train accuracy: 0.8939\n",
      "Val loss: 0.3512 \t Val accuracy: 0.8554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 10.99it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n",
      "Train loss: 0.2658 \t Train accuracy: 0.8946\n",
      "Val loss: 0.3503 \t Val accuracy: 0.8568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.03it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n",
      "Train loss: 0.2639 \t Train accuracy: 0.8952\n",
      "Val loss: 0.3495 \t Val accuracy: 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:13<00:00, 11.23it/s]\n",
      "  1%|          | 1/157 [00:00<00:20,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n",
      "Train loss: 0.2618 \t Train accuracy: 0.8963\n",
      "Val loss: 0.3486 \t Val accuracy: 0.8570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.16it/s]\n",
      "  1%|          | 1/157 [00:00<00:22,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n",
      "Train loss: 0.2600 \t Train accuracy: 0.8972\n",
      "Val loss: 0.3475 \t Val accuracy: 0.8572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.10it/s]\n",
      "  1%|          | 1/157 [00:00<00:22,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6\n",
      "Train loss: 0.2582 \t Train accuracy: 0.8979\n",
      "Val loss: 0.3469 \t Val accuracy: 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.15it/s]\n",
      "  1%|          | 1/157 [00:00<00:22,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7\n",
      "Train loss: 0.2561 \t Train accuracy: 0.8990\n",
      "Val loss: 0.3457 \t Val accuracy: 0.8576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.15it/s]\n",
      "  1%|▏         | 2/157 [00:00<00:08, 17.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8\n",
      "Train loss: 0.2546 \t Train accuracy: 0.8992\n",
      "Val loss: 0.3449 \t Val accuracy: 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.14it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9\n",
      "Train loss: 0.2527 \t Train accuracy: 0.8998\n",
      "Val loss: 0.3442 \t Val accuracy: 0.8598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.19it/s]\n",
      "  1%|          | 1/157 [00:00<00:16,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10\n",
      "Train loss: 0.2507 \t Train accuracy: 0.9010\n",
      "Val loss: 0.3433 \t Val accuracy: 0.8602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.21it/s]\n",
      "  1%|          | 1/157 [00:00<00:25,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11\n",
      "Train loss: 0.2490 \t Train accuracy: 0.9016\n",
      "Val loss: 0.3428 \t Val accuracy: 0.8624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.11it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12\n",
      "Train loss: 0.2475 \t Train accuracy: 0.9026\n",
      "Val loss: 0.3426 \t Val accuracy: 0.8626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.19it/s]\n",
      "  1%|▏         | 2/157 [00:00<00:14, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13\n",
      "Train loss: 0.2459 \t Train accuracy: 0.9039\n",
      "Val loss: 0.3414 \t Val accuracy: 0.8630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.12it/s]\n",
      "  1%|          | 1/157 [00:00<00:16,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14\n",
      "Train loss: 0.2442 \t Train accuracy: 0.9048\n",
      "Val loss: 0.3406 \t Val accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:13<00:00, 11.24it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15\n",
      "Train loss: 0.2422 \t Train accuracy: 0.9055\n",
      "Val loss: 0.3399 \t Val accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.13it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16\n",
      "Train loss: 0.2409 \t Train accuracy: 0.9055\n",
      "Val loss: 0.3399 \t Val accuracy: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.06it/s]\n",
      "  1%|          | 1/157 [00:00<00:17,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17\n",
      "Train loss: 0.2392 \t Train accuracy: 0.9071\n",
      "Val loss: 0.3388 \t Val accuracy: 0.8648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.07it/s]\n",
      "  1%|          | 1/157 [00:00<00:17,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18\n",
      "Train loss: 0.2377 \t Train accuracy: 0.9075\n",
      "Val loss: 0.3381 \t Val accuracy: 0.8646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.19it/s]\n",
      "  1%|          | 1/157 [00:00<00:16,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19\n",
      "Train loss: 0.2358 \t Train accuracy: 0.9082\n",
      "Val loss: 0.3379 \t Val accuracy: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.12it/s]\n",
      "  1%|          | 1/157 [00:00<00:24,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20\n",
      "Train loss: 0.2346 \t Train accuracy: 0.9089\n",
      "Val loss: 0.3371 \t Val accuracy: 0.8654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 11.04it/s]\n",
      "  1%|          | 1/157 [00:00<00:17,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 21\n",
      "Train loss: 0.2329 \t Train accuracy: 0.9101\n",
      "Val loss: 0.3365 \t Val accuracy: 0.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 10.80it/s]\n",
      "  1%|          | 1/157 [00:00<00:28,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 22\n",
      "Train loss: 0.2315 \t Train accuracy: 0.9102\n",
      "Val loss: 0.3360 \t Val accuracy: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:14<00:00, 10.65it/s]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 23\n",
      "Train loss: 0.2300 \t Train accuracy: 0.9106\n",
      "Val loss: 0.3359 \t Val accuracy: 0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:17<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 24\n",
      "Train loss: 0.2286 \t Train accuracy: 0.9116\n",
      "Val loss: 0.3352 \t Val accuracy: 0.8668\n"
     ]
    }
   ],
   "source": [
    "# Setup logging to Tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "model_name = 'bag_of_words_embeddings_from_scratch'\n",
    "log_file = f'./runs/{model_name}/{now}'\n",
    "writer = SummaryWriter(log_file)\n",
    "\n",
    "# training loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_epochs = 125\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # train\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    train_size = 0\n",
    "    running_accuracy = 0.0\n",
    "    for batch in tqdm(train_iter):\n",
    "        \n",
    "        # forward pass to compute the batch loss\n",
    "        x = batch.text\n",
    "        y = batch.label.long()\n",
    "        predictions = model(x)        \n",
    "        loss = criterion(predictions, y)\n",
    "            \n",
    "        # backward pass to update model parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute train metrics\n",
    "        running_loss += loss.data * x.size(0)\n",
    "        _, predicted_classes = torch.max(predictions, 1)\n",
    "        running_accuracy += predicted_classes.eq(y.data).sum().item()\n",
    "        train_size += x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / train_size\n",
    "    writer.add_scalar('training_epoch_loss', epoch_loss, epoch + 1)\n",
    "    epoch_accuracy = running_accuracy / train_size\n",
    "    writer.add_scalar('training_epoch_accuracy', epoch_accuracy, epoch + 1)\n",
    "    \n",
    "    # validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()\n",
    "    val_size = 0\n",
    "    val_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_iter:\n",
    "            x = batch.text\n",
    "            y = batch.label.long()\n",
    "            predictions = model(x)\n",
    "            loss = criterion(predictions, y)\n",
    "            \n",
    "            # compute validation metrics\n",
    "            val_loss += loss.data * x.size(0)\n",
    "            _, predicted_classes = torch.max(predictions, 1)\n",
    "            val_accuracy += predicted_classes.eq(y.data).sum().item()           \n",
    "            val_size += x.size(0)\n",
    "            \n",
    "        val_loss /= val_size\n",
    "        val_accuracy /= val_size\n",
    "        \n",
    "        print('\\nEpoch: {}'.format(epoch))\n",
    "        print('Train loss: {:.4f} \\t Train accuracy: {:.4f}'.format(epoch_loss, epoch_accuracy))\n",
    "        print('Val loss: {:.4f} \\t Val accuracy: {:.4f}'.format(val_loss, val_accuracy))\n",
    "        writer.add_scalar('validation_epoch_loss', val_loss, epoch + 1)\n",
    "        writer.add_scalar('validation_epoch_accuracy', val_accuracy, epoch + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 5: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Visualize the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
